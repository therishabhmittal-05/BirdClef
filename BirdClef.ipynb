{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport librosa \nimport matplotlib.pyplot as plt\nimport cv2 as cv\nfrom tqdm import tqdm\nimport math\nimport os\nimport torch \nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision\nfrom torchvision.models import efficientnet_v2_m, EfficientNet_V2_M_Weights\nfrom torch.amp import autocast, GradScaler\nfrom torchmetrics.classification import BinaryAUROC\nfrom torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:53:55.606030Z","iopub.execute_input":"2025-05-14T16:53:55.607268Z","iopub.status.idle":"2025-05-14T16:53:57.429399Z","shell.execute_reply.started":"2025-05-14T16:53:55.607238Z","shell.execute_reply":"2025-05-14T16:53:57.428816Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:54:00.817678Z","iopub.execute_input":"2025-05-14T16:54:00.818209Z","iopub.status.idle":"2025-05-14T16:54:00.873265Z","shell.execute_reply.started":"2025-05-14T16:54:00.818181Z","shell.execute_reply":"2025-05-14T16:54:00.872404Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/birdclef-2025/train.csv\")\ntaxo_df = pd.read_csv(\"/kaggle/input/birdclef-2025/taxonomy.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:54:04.066646Z","iopub.execute_input":"2025-05-14T16:54:04.067338Z","iopub.status.idle":"2025-05-14T16:54:04.195753Z","shell.execute_reply.started":"2025-05-14T16:54:04.067279Z","shell.execute_reply":"2025-05-14T16:54:04.195011Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df = train_df[[\"primary_label\", \"filename\", \"scientific_name\"]].copy()\ndf = df.sort_values(by=\"primary_label\")\nprim_class_ = taxo_df.set_index('primary_label')['class_name'].to_dict()\ndf['label'] = df['primary_label'].astype(str).map(prim_class_) + '_' + df['primary_label'].astype(str)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:54:05.095298Z","iopub.execute_input":"2025-05-14T16:54:05.095613Z","iopub.status.idle":"2025-05-14T16:54:05.140561Z","shell.execute_reply.started":"2025-05-14T16:54:05.095589Z","shell.execute_reply":"2025-05-14T16:54:05.139892Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T17:11:46.691063Z","iopub.execute_input":"2025-05-14T17:11:46.691337Z","iopub.status.idle":"2025-05-14T17:11:46.702960Z","shell.execute_reply.started":"2025-05-14T17:11:46.691316Z","shell.execute_reply":"2025-05-14T17:11:46.702146Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"      primary_label               filename        scientific_name  \\\n0           1139490   1139490/CSA36385.ogg   Ragoniella pulchella   \n1           1139490   1139490/CSA36389.ogg   Ragoniella pulchella   \n2           1192948   1192948/CSA36358.ogg  Oxyprora surinamensis   \n3           1192948   1192948/CSA36366.ogg  Oxyprora surinamensis   \n4           1192948   1192948/CSA36373.ogg  Oxyprora surinamensis   \n...             ...                    ...                    ...   \n28469        ywcpar    ywcpar/XC382486.ogg   Amazona ochrocephala   \n28470        ywcpar    ywcpar/XC401617.ogg   Amazona ochrocephala   \n28471        ywcpar    ywcpar/XC407235.ogg   Amazona ochrocephala   \n28465        ywcpar    ywcpar/XC375635.ogg   Amazona ochrocephala   \n28563        ywcpar  ywcpar/iNat922688.ogg   Amazona ochrocephala   \n\n                 label  \n0      Insecta_1139490  \n1      Insecta_1139490  \n2      Insecta_1192948  \n3      Insecta_1192948  \n4      Insecta_1192948  \n...                ...  \n28469      Aves_ywcpar  \n28470      Aves_ywcpar  \n28471      Aves_ywcpar  \n28465      Aves_ywcpar  \n28563      Aves_ywcpar  \n\n[28564 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>primary_label</th>\n      <th>filename</th>\n      <th>scientific_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1139490</td>\n      <td>1139490/CSA36385.ogg</td>\n      <td>Ragoniella pulchella</td>\n      <td>Insecta_1139490</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1139490</td>\n      <td>1139490/CSA36389.ogg</td>\n      <td>Ragoniella pulchella</td>\n      <td>Insecta_1139490</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1192948</td>\n      <td>1192948/CSA36358.ogg</td>\n      <td>Oxyprora surinamensis</td>\n      <td>Insecta_1192948</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1192948</td>\n      <td>1192948/CSA36366.ogg</td>\n      <td>Oxyprora surinamensis</td>\n      <td>Insecta_1192948</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1192948</td>\n      <td>1192948/CSA36373.ogg</td>\n      <td>Oxyprora surinamensis</td>\n      <td>Insecta_1192948</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28469</th>\n      <td>ywcpar</td>\n      <td>ywcpar/XC382486.ogg</td>\n      <td>Amazona ochrocephala</td>\n      <td>Aves_ywcpar</td>\n    </tr>\n    <tr>\n      <th>28470</th>\n      <td>ywcpar</td>\n      <td>ywcpar/XC401617.ogg</td>\n      <td>Amazona ochrocephala</td>\n      <td>Aves_ywcpar</td>\n    </tr>\n    <tr>\n      <th>28471</th>\n      <td>ywcpar</td>\n      <td>ywcpar/XC407235.ogg</td>\n      <td>Amazona ochrocephala</td>\n      <td>Aves_ywcpar</td>\n    </tr>\n    <tr>\n      <th>28465</th>\n      <td>ywcpar</td>\n      <td>ywcpar/XC375635.ogg</td>\n      <td>Amazona ochrocephala</td>\n      <td>Aves_ywcpar</td>\n    </tr>\n    <tr>\n      <th>28563</th>\n      <td>ywcpar</td>\n      <td>ywcpar/iNat922688.ogg</td>\n      <td>Amazona ochrocephala</td>\n      <td>Aves_ywcpar</td>\n    </tr>\n  </tbody>\n</table>\n<p>28564 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# Important\nalllabels = set()\nfor sample in df.primary_label:\n    alllabels.add(sample)\n\nalllabels = sorted(list(alllabels))\nn_labels = len(alllabels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:54:11.024088Z","iopub.execute_input":"2025-05-14T16:54:11.024382Z","iopub.status.idle":"2025-05-14T16:54:11.032887Z","shell.execute_reply.started":"2025-05-14T16:54:11.024362Z","shell.execute_reply":"2025-05-14T16:54:11.032332Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class Config:\n    out_dir = \"/kaggle/working/mel_spectrograms/\"\n    in_dir = \"/kaggle/input/birdclef-2025/train_audio/\"\n    fs = 32000\n\n    n_fft = 1024\n    hop_length = 256\n    n_mels = 64\n    fmin = 50\n    fmax = 12000\n\n    target_dur = 5\n    target_shape = (256, 256)\n\nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:54:15.364368Z","iopub.execute_input":"2025-05-14T16:54:15.365097Z","iopub.status.idle":"2025-05-14T16:54:15.369292Z","shell.execute_reply.started":"2025-05-14T16:54:15.365070Z","shell.execute_reply":"2025-05-14T16:54:15.368402Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# import IPython.display as ip\n# audio_ = config.in_dir+df.filename[10]\n# label = df.label[10]\n# print(label)\n# ip.Audio(audio_)\n# y, sr = librosa.load(config.in_dir + df.filename[10])\n# mel_spec_test = librosa.feature.melspectrogram(\n#     y=y, \n#     sr=sr,\n#     n_fft=config.n_fft,\n#     hop_length=config.hop_length,\n#     n_mels=config.n_mels,\n#     fmin=config.fmin,\n#     fmax=config.fmax,\n# )\n# mel_db = librosa.power_to_db(mel_spec_test, ref=np.max)\n# librosa.display.specshow(mel_db)\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def audio2mel(audio_):\n    if np.isnan(audio_).any():\n        mean_ = np.nanmean(audio_)\n        audio_ = np.nan_to_num(audio_, nan = mean_)\n\n    mel_spec = librosa.feature.melspectrogram(\n        y=audio_,\n        sr=config.fs,\n        n_fft=config.n_fft,\n        hop_length=config.hop_length,\n        n_mels=config.n_mels,\n        fmin=config.fmin,\n        fmax=config.fmax,\n        power=2.0\n    )\n    mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n    mel_db = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-8)\n    return mel_db","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(config.out_dir, exist_ok=True)\nfor i, row in tqdm(df.iterrows(), total=len(df)):\n    audio_, _  = librosa.load(config.in_dir + row.filename, sr=config.fs)\n    target_samp = int(config.target_dur * config.fs)\n\n    if len(audio_) < target_samp:\n        n_copy = math.ceil(target_samp/len(audio_))\n        if n_copy > 1:\n            audio_ = np.concatenate([audio_] * n_copy)\n    start = max(0, int(len(audio_)/2 - target_samp/2))\n    end = min(len(audio_), start+target_samp)\n\n    audio_ = audio_[start:end]\n    if len(audio_) < target_samp:\n        audio_ = np.pad(audio_, (0, target_samp - len(audio_)), mode='constant')\n    mel_spec = audio2mel(audio_)\n    if mel_spec.shape != config.target_shape:\n        mel_spec = cv.resize(mel_spec, config.target_shape, interpolation=cv.INTER_LINEAR)\n\n    out_path = f\"{config.out_dir}{row.label}_{i}.npy\"\n    np.save(out_path, mel_spec.astype(np.float32))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # !ls ./mel_spectrograms | head -2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BirdClefDs(Dataset):\n    def __init__(self, mel_dir, alllabels, n_labels):\n        self.mel_dir = mel_dir\n        self.files = [f for f in os.listdir(mel_dir) if f.endswith(\".npy\")]\n        self.alllabels = alllabels # sorted labels list, keep it consistent\n        self.n_labels = n_labels\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, id_):\n        filename = self.files[id_]\n        filepath = os.path.join(self.mel_dir, filename)\n\n        img = np.load(filepath).astype(np.float32)\n        \n        if img.ndim == 2:\n            img = np.expand_dims(img, axis = 0)\n            \n        img = torch.from_numpy(img)\n        img = img.repeat(3, 1, 1) \n        label_id = self.alllabels.index(filename.split('_')[1])\n        label = torch.zeros(self.n_labels, dtype=torch.float32) # one hot encoding\n        label[label_id] = 1.0\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:54:47.275343Z","iopub.execute_input":"2025-05-14T16:54:47.275930Z","iopub.status.idle":"2025-05-14T16:54:47.281948Z","shell.execute_reply.started":"2025-05-14T16:54:47.275901Z","shell.execute_reply":"2025-05-14T16:54:47.281078Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"BirdClef = BirdClefDs(config.out_dir, alllabels, n_labels)\n\nfor i, (sample, label) in enumerate(BirdClef):\n    print(f\"{i}: {sample.size()}, {label}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:54:48.182030Z","iopub.execute_input":"2025-05-14T16:54:48.182659Z","iopub.status.idle":"2025-05-14T16:54:48.214014Z","shell.execute_reply.started":"2025-05-14T16:54:48.182637Z","shell.execute_reply":"2025-05-14T16:54:48.213238Z"}},"outputs":[{"name":"stdout","text":"0: torch.Size([3, 256, 256]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"train_size = int(0.8 * len(BirdClef))\nval_size = len(BirdClef) - train_size\nBirdClef_train, BirdClef_val = random_split(BirdClef, [train_size, val_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:55:18.328679Z","iopub.execute_input":"2025-05-14T16:55:18.329565Z","iopub.status.idle":"2025-05-14T16:55:18.335357Z","shell.execute_reply.started":"2025-05-14T16:55:18.329532Z","shell.execute_reply":"2025-05-14T16:55:18.334733Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"batch_size=8\ntrain_ = DataLoader(BirdClef_train, batch_size=batch_size, shuffle=True, num_workers=4)\nval_ = DataLoader(BirdClef_val, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:55:19.961761Z","iopub.execute_input":"2025-05-14T16:55:19.962101Z","iopub.status.idle":"2025-05-14T16:55:19.966645Z","shell.execute_reply.started":"2025-05-14T16:55:19.962077Z","shell.execute_reply":"2025-05-14T16:55:19.965998Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# for x, y in train_:\n#     print(f\"{x.shape} : {y.shape}\")\n#     print(f\"{x} : {y}\")\n#     break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:56:27.222130Z","iopub.execute_input":"2025-05-14T16:56:27.222787Z","iopub.status.idle":"2025-05-14T16:56:27.226814Z","shell.execute_reply.started":"2025-05-14T16:56:27.222760Z","shell.execute_reply":"2025-05-14T16:56:27.226015Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class Model_01(nn.Module):\n    def __init__(self, n_labels):\n        super().__init__()\n        base = efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n        \n        self.features = base.features\n        self.avg_pool = base.avgpool\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.4),\n            nn.Linear(base.classifier[1].in_features, n_labels)\n        )\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avg_pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:55:28.318649Z","iopub.execute_input":"2025-05-14T16:55:28.319367Z","iopub.status.idle":"2025-05-14T16:55:28.324379Z","shell.execute_reply.started":"2025-05-14T16:55:28.319340Z","shell.execute_reply":"2025-05-14T16:55:28.323468Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model = Model_01(n_labels).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:55:30.293899Z","iopub.execute_input":"2025-05-14T16:55:30.294184Z","iopub.status.idle":"2025-05-14T16:55:31.757470Z","shell.execute_reply.started":"2025-05-14T16:55:30.294166Z","shell.execute_reply":"2025-05-14T16:55:31.756867Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# summary(model, input_size=(3, 256, 256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:56:07.889587Z","iopub.execute_input":"2025-05-14T16:56:07.890341Z","iopub.status.idle":"2025-05-14T16:56:07.894100Z","shell.execute_reply.started":"2025-05-14T16:56:07.890306Z","shell.execute_reply":"2025-05-14T16:56:07.893288Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"lr = 1e-4\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:55:52.828084Z","iopub.execute_input":"2025-05-14T16:55:52.828383Z","iopub.status.idle":"2025-05-14T16:55:52.835795Z","shell.execute_reply.started":"2025-05-14T16:55:52.828361Z","shell.execute_reply":"2025-05-14T16:55:52.835107Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# output = model(x.to(device))\n# output.shape, y.shape\n# auroc = BinaryAUROC()\n# auc_score = auroc(output.cpu(), y)\n\n# print(f\"AUROC score: {auc_score}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T16:56:30.573101Z","iopub.execute_input":"2025-05-14T16:56:30.573386Z","iopub.status.idle":"2025-05-14T16:56:30.703409Z","shell.execute_reply.started":"2025-05-14T16:56:30.573365Z","shell.execute_reply":"2025-05-14T16:56:30.702769Z"}},"outputs":[{"name":"stdout","text":"AUROC score: 0.26722562313079834\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(output[0].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T17:17:17.162651Z","iopub.execute_input":"2025-05-14T17:17:17.163340Z","iopub.status.idle":"2025-05-14T17:17:17.167725Z","shell.execute_reply.started":"2025-05-14T17:17:17.163316Z","shell.execute_reply":"2025-05-14T17:17:17.166701Z"}},"outputs":[{"name":"stdout","text":"torch.Size([206])\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def train(model, train_, criterion, optimizer, scheduler, n_epochs=30):\n    losses = []\n    auroces = []\n    scaler = GradScaler(device=device)\n    metric = BinaryAUROC().to(device)\n    \n    for epoch in range(n_epochs):\n        model.train()\n        running_loss = 0.0\n        \n        for sample, label in tqdm(train_, total=len(train_)):\n            sample = sample.to(device)\n            label = label.to(device)\n    \n            optimizer.zero_grad()\n            \n            with autocast(device_type=device):\n                yhat = model(sample)\n                loss = criterion(yhat, label)\n                \n            scaler.scale(loss).backward() # loss.backward()\n            scaler.step(optimizer) # optimizer.step()\n            scaler.update()\n                        \n            running_loss += loss.item() * sample.size(0)\n            metric.update(yhat.sigmoid(), label)\n        \n        auroc = metric.compute().item()\n        epoch_loss = running_loss / len(train_.dataset)\n\n        losses.append(epoch_loss)\n        auroces.append(auroc)\n        metric.reset()\n        \n        print(f'Epoch {epoch+1}/{n_epochs} - Loss: {epoch_loss:.4f}, ROC: {auroc:.4f}')\n        scheduler.step(epoch_loss)\n        \n    return losses, auroces\n\nlosses, auroces = train(model, train_, criterion, optimizer, scheduler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T17:17:39.571402Z","iopub.execute_input":"2025-05-14T17:17:39.571689Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2857/2857 [07:40<00:00,  6.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Loss: 0.0298, ROC: 0.8259\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2857/2857 [07:42<00:00,  6.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/30 - Loss: 0.0199, ROC: 0.9204\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2857/2857 [07:37<00:00,  6.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/30 - Loss: 0.0186, ROC: 0.9325\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2857/2857 [07:36<00:00,  6.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/30 - Loss: 0.0181, ROC: 0.9372\n","output_type":"stream"},{"name":"stderr","text":" 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2072/2857 [05:31<02:04,  6.29it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(losses, auroces)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(losses)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(auroces)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, val_, criterion):\n    model.eval()\n    val_loss = 0.0\n    metric = BinaryAUROC().to(device)\n    with torch.no_grad():\n        for sample, label in tqdm(val_):\n            sample = sample.to(device)\n            label = label.to(device) \n            \n            with autocast(device_type=device):\n                y_pred = model(sample)\n                loss = criterion(y_pred.sigmoid(), label)\n                \n            metric.update(y_pred.sigmoid(), label)    \n            val_loss += loss.item() *  sample.size(0)\n            \n    auroc = metric.compute().item()     \n    val_loss /= len(val_.dataset)\n    return val_loss, auroc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_loss, auroc = evaluate(model, val_, criterion)\nprint(f\"Validation Loss: {val_loss:.4f} | ROC: {auroc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}